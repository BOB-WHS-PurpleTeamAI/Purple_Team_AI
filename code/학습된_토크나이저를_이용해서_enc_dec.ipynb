{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_PU6fmpXxRX",
        "outputId": "20069686-1267-42ad-b5ea-7c5388da8d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from logging import getLogger\n",
        "from typing import List\n",
        "import torch\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "import json\n",
        "\n",
        "logger = getLogger()"
      ],
      "metadata": {
        "id": "9CMf5aF0YNe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tokenizer():\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      model_path = \"pytest.model\"\n",
        "      assert os.path.isfile(model_path), model_path\n",
        "      self.sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "      logger.info(f\"Reloaded SentencePiece model from {model_path}\")\n",
        "  def encode(self,lines):\n",
        "    out = []\n",
        "    for line in lines:\n",
        "      ids = self.sp_model.encode_as_ids(line)\n",
        "      out.append(torch.tensor(ids))\n",
        "    out = torch.nn.utils.rnn.pad_sequence(out, batch_first=True, padding_value=0)\n",
        "    return out\n",
        "  def decode(self,lines):\n",
        "    out =[]\n",
        "    for line in lines:\n",
        "      line=line.tolist()\n",
        "      txt=self.sp_model.decode_ids(line)\n",
        "      out.append(txt)\n",
        "    return out"
      ],
      "metadata": {
        "id": "HnHnsC74YQuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트"
      ],
      "metadata": {
        "id": "29mGgrZ1YkxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines=[\"for i in a\",\"print(lamda x:for i in range(x)\"]\n",
        "tok=tokenizer()\n",
        "print(tok.encode(lines))\n",
        "print(tok.decode(tok.encode(lines)))"
      ],
      "metadata": {
        "id": "lenuTWr2YV4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설정 불러오기"
      ],
      "metadata": {
        "id": "74BhOrOFe-uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)\n",
        "mconfig=Config.load(\"config.json\")\n",
        "print(mconfig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOoD6UcRe9Bw",
        "outputId": "04e0b37b-15de-4099-8bfc-9f0a5196f8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_enc_vocab': 0, 'n_dec_vocab': 0, 'n_enc_seq': 512, 'n_dec_seq': 512, 'n_layer': 12, 'd_hidn': 768, 'i_pad': 0, 'd_ff': 3072, 'n_head': 12, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'n_output': 2, 'weight_decay': 0, 'learning_rate': 5e-05, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'context_window': 16}\n"
          ]
        }
      ]
    }
  ]
}